% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fregre.kam.fr.R
\name{fregre.kam.fr}
\alias{fregre.kam.fr}
\title{Functional Kernel Additive regression with functional response.}
\usage{
fregre.kam.fr(
  formula,
  data,
  weights = rep(1, nobs),
  par.metric = NULL,
  par.np = NULL,
  control = list(maxit = 100, epsilon = 0.001, trace = FALSE, inverse = "solve")
)
}
\arguments{
\item{formula}{an object of class "\link{formula}": a symbolic description of the model to be fitted (as a linear model).}

\item{data}{an \code{ldata} object (a list with the collection of functional covariates and response)}

\item{weights}{an optional vector of weights to be used in the estimation process.}

\item{par.metric}{list with components with the names in \code{formula} containing the details of each metric/semimetric to be applied 
to each covariate/response. The first component of that list called \code{metric} is the name of the function to be applied, the rest are the possible parameters for that metric}

\item{par.np}{List with components with the names of the covariates like in \code{formula} containing the needed components
for the smoothing task: \code{Ker} kernel, \code{type.S} type of smoothing, \code{par.S} parameters for smoothing, \code{h} bandwidths. 
Values by default are provided when \code{par.np[[]]} is NULL.}

\item{control}{List of components \code{maxit}:maximum number of iterations, \code{epsilon}: relative change in objective functions, 
\code{trace}: TRUE/FALSE to show intermediate results and \code{inverse}: "solve"/"svd" way of computing the inverse.}
}
\value{
Return:
\itemize{
\item \code{result}{ List with the output of each component.} 
\item \code{residuals}{ \code{y} minus \code{fitted values}.} 
\item \code{fitted.values}{ Estimated scalar response.}
\item \code{H}{ The hat matrix.}
\item \code{effects}{ List with the contribution to \code{fitted.values} of each component.}
\item \code{alpha}{ Estimation of the intercept.}
\item \code{metric}{ List with the metric employed with each component.}
\item \code{par.metric}{ Options for the metric for each component.}
\item \code{RSS}{ Functional Residual Sum of Squares.}
\item \code{null.RSS} { Functional Residual Sum of Squares of the null model: \eqn{y-\bar{y}}}
\item \code{sr2}{ Residual variance.} 
\item \code{df}{ The residual degrees of freedom computed from \code{H}} 
\item \code{iter}{ Number of iterations consumed.} 
\item \code{weights}{ weights}. 
\item \code{eqrank}{ Degrees of freedom consumed by each component.} 
\item \code{converged}{ Final status of the iterations.}
}
}
\description{
Computes Functional Kernel Additive Regression between functional explanatory variables and
a functional response
}
\details{
The non-parametric functional regression model can be written as follows
\deqn{ y_i =r_1(X^{(1)}_i)+...+ r_p(X^{(p)}_i)+\epsilon_i } where the unknown smooth real functions
\eqn{r_j} are estimated using kernel estimation and backfitting: 
\deqn{\hat{r}(X_0)=\hat{\alpha}+\hat{r}_1(X^{(1)}_0)+...+\hat{r}_p(X^{(p)}_0)} with
\deqn{\hat{r_j}(X^{(j)}_0)=\frac{\sum_{i=1}^{n}{K(h_{j}^{-1}d_j(X^{(j)}_0,X^{(j)}_{i}))(y_{i}-\hat{y}^{(-j)}_{i})}}{\sum_{i=1}^{n}{K(h_{j}^{-1}d_j(X^{(j)}_0,X^{(j)}_i))}}}
where \eqn{K} is a kernel function (see \code{Ker} argument), \code{h} is the vector of the smoothing parameter
and \eqn{d_j} is a metric or a semi-metric (see \code{metric} argument).

The function estimates the value of smoothing parameter for each component (also called
bandwidth) \code{h} through Generalized Cross-validation \code{GCV} criterium (see \code{GCV.S.fr} or \code{CV.S.fr}) and
computing the distances using a metric or a semimetric (see, for instance, \code{\link{metric.lp}}). 
Different asymmetric kernels can be used, see \code{\link{Kernel.asymmetric}}.\cr
}
\examples{
\dontrun{
N=100
T=51
S=31
tj = seq(0,1,len=T)
si = seq(0,5,len=S)
X1 = rproc2fdata(N,tj,sigma="OU")
X2 = rproc2fdata(N,tj,sigma="vexponential")
X3 = rproc2fdata(N,tj,sigma="brownian")
beta1<-fdata(tj^2+3*tj^4,argvals=tj)
beta2<-fdata(4*(tj-0.5)^2,argvals=tj)
beta3<-fdata(exp(-tj^2/2),argvals=tj)
beta4<-outer(si,tj,function(si,tj){exp(-5*abs(tj-si/5))})
beta5<-outer(si,tj,function(si,tj){3*tj*si/5+tj^2*exp(-si/5)})
beta6<-outer(si,tj,function(si,tj){-3*abs(tj-si/5)+3*tj*si/5})
expX1 = exp(X1)
X3d=X3
X3d$data=sweep(sweep(X3d$data+0.001,2,beta2$data,"*"),2,beta3$data,"+")
FX1=fdata(t(beta4\%*\%t(expX1$data)),si)
FX2=fdata(t(beta5\%*\%t(X2$data)),si)
FX3=fdata(t(beta6\%*\%t(X3d$data)),si)
epsilon = rproc2fdata(N,si,sigma="vexponential",par.list=list(scale=.1,theta=2))
yt=FX1+FX2+FX3+epsilon
y1=FX1+epsilon
y2=FX2+epsilon
y3=FX3+epsilon
ldata=ldata(df=data.frame(idx=1:nrow(yt)),yt=yt,y1=y1,y2=y2,y3=y3,X1=X1,X2=X2,X3=X3)
pmetric=list(yt=list(metric=metric.lp,lp=1),y1=list(metric=metric.lp,lp=1),
             y2=list(metric=metric.lp,lp=1),y3=list(metric=metric.lp,lp=1),
X1=list(metric=metric.lp),X2=list(metric=metric.lp),X3=list(metric=metric.lp))
modt=fregre.kam.fr(yt~X1+X2+X3,data=ldata,par.metric=pmetric,control=list(trace=TRUE))
modt0=fregre.kam.fr(yt~X1+X2+X3,data=ldata,control=list(trace=TRUE))

modt1=fregre.kam.fr(y1~X1+X2+X3,data=ldata,par.metric=pmetric,control=list(trace=TRUE))
modt2=fregre.kam.fr(y2~X1+X2+X3,data=ldata,par.metric=pmetric,control=list(trace=TRUE))
modt3=fregre.kam.fr(y3~X1+X2+X3,data=ldata,par.metric=pmetric,control=list(trace=TRUE))
}

}
\references{
Ferraty, F. and Vieu, P. (2006). \emph{Nonparametric functional
data analysis.} Springer Series in Statistics, New York.

Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  \emph{Statistical
Computing in Functional Data Analysis: The R Package fda.usc.} Journal of
Statistical Software, 51(4), 1-28. \url{https://www.jstatsoft.org/v51/i04/}
}
\seealso{
See Also as: \code{\link{fregre.np.cv.fr}},
\code{\link{summary.fregre.fd}} and \code{\link{predict.fregre.fd}} .\cr
Alternative method: \code{fregre.lm.fr} and \code{\link{fregre.np.cv.fr}}.
}
\author{
Manuel Febrero-Bande, Manuel Oviedo de la Fuente
\email{manuel.oviedo@udc.es}
}
\keyword{regression}
